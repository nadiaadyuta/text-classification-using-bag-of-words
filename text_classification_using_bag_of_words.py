# -*- coding: utf-8 -*-
"""Text Classification using Bag of Words

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X5lrzsTrGAQ9v4__TBiz_3JqPGL2EuPQ

# **Import Depedencies**
"""

import nltk
nltk.download('all')

"""# **Inisialisasi Teks Rujukan (Data Train)**

Dipilih 3 topik terkait Kesehatan, Olahraga, dan Keuangan. Berikut teks rujukan untuk masing-masing topik:

* **Kesehatan** <br>
"The Ministry of Health recorded 27 cases of death in the Election Organizing Team (KPPS) officers in the 2024 elections. Head of the Ministry's Communication and Public Services Bureau Siti Nadia Tarmizi said on Friday (2/16) that the causes of death among KPPS officers included nine deaths from heart disease, four from accidental injuries, two from septic shock, one from acute respiratory distress syndrome, one from hypertension, two deaths without comorbidities, and eight others who died en route to the hospital and are being confirmed. Health Minister Budi Gunadi Sadikin said the number of deaths of KPPS officers in this year's election had decreased compared to the previous election in 2019, which recorded 894 deaths. Minister Budi expressed hope that no deaths among KPPS officers would be reported in the future elections. One of the efforts is to conduct health screening for KPPS officers, as was done in this year's election."

* **Sepak Bola** <br>
"The Indonesia U23 National Team claimed a crucial 1-0 victory over Australia in their second Group A match at the AFC U23 Asian Cup 2024, held at the Abdullah bin Khalifa Stadium in Doha, Qatar, on Thursday (4/18). In a tense first half, Australia had a golden opportunity to take the lead from the penalty spot, but their effort was expertly saved by Indonesia's goalkeeper, Ernando Ari Sutaryadi. Garuda Muda then broke the deadlock in the 45th minute through a Komang Teguh header, following a teasing cross from Nathan Tjoe-A-On from a corner kick. The second half saw both teams pushing for a goal, but neither side could find the back of the net until the final whistle blew. Indonesia U23 will now face Jordan on April 21 in their next match."

* **Keuangan** <br>
"Starting July 1, 2024, people earning less than $43,888 per year, or $844 per week, would be eligible for overtime pay. By January 1, 2025, that salary threshold would increase to $58,656 per year, or $1,128 per week. The rule also includes automatic increases to that salary eligibility level every three years, starting in 2027, to keep pace with the changing labor market and wages. The current salary threshold to qualify for overtime pay is $35,568 per year based on a limit set by the Trump administration in 2019 — the first increase since 2004."
"""

# Inisialisasi teks
teks_kesehatan = "The Ministry of Health recorded 27 cases of death in the Election Organizing Team (KPPS) officers in the 2024 elections. Head of the Ministry's Communication and Public Services Bureau Siti Nadia Tarmizi said on Friday (2/16) that the causes of death among KPPS officers included nine deaths from heart disease, four from accidental injuries, two from septic shock, one from acute respiratory distress syndrome, one from hypertension, two deaths without comorbidities, and eight others who died en route to the hospital and are being confirmed. Health Minister Budi Gunadi Sadikin said the number of deaths of KPPS officers in this year's election had decreased compared to the previous election in 2019, which recorded 894 deaths. Minister Budi expressed hope that no deaths among KPPS officers would be reported in the future elections. One of the efforts is to conduct health screening for KPPS officers, as was done in this year's election."
teks_sepak_bola = "The Indonesia U23 National Team claimed a crucial 1-0 victory over Australia in their second Group A match at the AFC U23 Asian Cup 2024, held at the Abdullah bin Khalifa Stadium in Doha, Qatar, on Thursday (4/18). In a tense first half, Australia had a golden opportunity to take the lead from the penalty spot, but their effort was expertly saved by Indonesia's goalkeeper, Ernando Ari Sutaryadi. Garuda Muda then broke the deadlock in the 45th minute through a Komang Teguh header, following a teasing cross from Nathan Tjoe-A-On from a corner kick. The second half saw both teams pushing for a goal, but neither side could find the back of the net until the final whistle blew. Indonesia U23 will now face Jordan on April 21 in their next match."
teks_keuangan = "Starting July 1, 2024, people earning less than  43,888peryear,or 844 per week, would be eligible for overtime pay. By January 1, 2025, that salary threshold would increase to  58,656peryear,or 1,128 per week. The rule also includes automatic increases to that salary eligibility level every three years, starting in 2027, to keep pace with the changing labor market and wages. The current salary threshold to qualify for overtime pay is $35,568 per year based on a limit set by the Trump administration in 2019 — the first increase since 2004."

# Ubah menjadi lower case
teks_kesehatan_lower = teks_kesehatan.lower()
teks_sepak_bola_lower = teks_sepak_bola.lower()
teks_keuangan_lower = teks_keuangan.lower()

# Tampilkan hasilnya
print(teks_kesehatan_lower,'\n')
print(teks_sepak_bola_lower,'\n')
print(teks_keuangan_lower)

"""# **Tokenization**"""

# Import library nltk
from nltk import tokenize

# Proses tokenisasi untuk kesehatan mental
token_kesehatan = tokenize.word_tokenize(teks_kesehatan_lower)

# Tampilkan hasilnya
print(token_kesehatan)

# Proses tokenisasi untuk sepak bola
token_sepak_bola = tokenize.word_tokenize(teks_sepak_bola_lower)

# Tampilkan hasilnya
print(token_sepak_bola)

# Proses tokenisasi untuk pasar saham
token_keuangan = tokenize.word_tokenize(teks_keuangan_lower)

# Tampilkan hasilnya
print(token_keuangan)

"""## **Removing Stopwords & Punctuations**

Jika kata pada hasil tokenisasi merupakan stopwords atau punctuations (tanda baca) maka akan dihapus
"""

# Import library
from nltk import corpus

# Stopwords pada bahasa inggris
stopword_english = corpus.stopwords.words('english')

# Tampilkan stopwords
print(stopword_english)

# Import library
import string

# Punctuations
str_punct = string.punctuation

# Tampilkan punctuations
print(str_punct)

# Proses menghapus stopwords dan punctuations (tanda baca) pada token kesehatan mental
for kata in token_kesehatan:
    if(kata in stopword_english or kata in str_punct):
        token_kesehatan.remove(kata)

# Tampilkan hasilnya
print(token_kesehatan)

# Proses menghapus stopwords dan punctuations (tanda baca) pada token sepak bola
for kata in token_sepak_bola:
    if(kata in stopword_english or kata in str_punct):
        token_sepak_bola.remove(kata)

# Tampilkan hasilnya
print(token_sepak_bola)

# Proses menghapus stopwords dan punctuations (tanda baca) pada token pasar saham
for kata in token_keuangan:
    if(kata in stopword_english or kata in str_punct):
        token_keuangan.remove(kata)

# Tampilkan hasilnya
print(token_keuangan)

"""# **Lemmatization**

Proses membuang karakter imbuhan
"""

# Import library yang dibutuhkan
from nltk import stem

# Buat object dari class WordNetLemmatizer
lemmatizer = stem.WordNetLemmatizer()

# Buat list kosong untuk menampung hasil lemmatization
token_kesehatan_lemmatized = list()

# Proses lemmatization pada token kesehatan mental
for kata in token_kesehatan:
    lemmatized = lemmatizer.lemmatize(kata, pos = 'v')
    token_kesehatan_lemmatized.append(lemmatized)

# Tampilkan hasilnya
print(token_kesehatan_lemmatized)

# Buat list kosong untuk menampung hasil lemmatization
token_sepak_bola_lemmatized = list()

# Proses lemmatization pada token sepak bola
for kata in token_sepak_bola:
    lemmatized = lemmatizer.lemmatize(kata, pos = 'v')
    token_sepak_bola_lemmatized.append(lemmatized)

# Tampilkan hasilnya
print(token_sepak_bola_lemmatized)

# Buat list kosong untuk menampung hasil lemmatization
token_keuangan_lemmatized = list()

# Proses lemmatization pada token pasar saham
for kata in token_keuangan:
    lemmatized = lemmatizer.lemmatize(kata, pos = 'v')
    token_keuangan_lemmatized.append(lemmatized)

# Tampilkan hasilnya
print(token_keuangan_lemmatized)

# Coba tampilkan perbandingannya
print(f'Token sebelum di lemmatization : {token_kesehatan}')
print(f'Token setelah di lemmatization : {token_kesehatan_lemmatized}\n')

print(f'Token sebelum di lemmatization : {token_sepak_bola}')
print(f'Token setelah di lemmatization : {token_sepak_bola_lemmatized}\n')

print(f'Token sebelum di lemmatization : {token_keuangan}')
print(f'Token setelah di lemmatization : {token_keuangan_lemmatized}\n')

"""# **Ubah Kembali Menjadi String & Gabungkan Hasilnya**"""

# Proses mengubah list menjadi teks
token_kesehatan_lemmatized_text = " ".join(token_kesehatan_lemmatized)

# Tampilkan hasilnya
print(token_kesehatan_lemmatized_text)

# Proses mengubah list menjadi teks
token_sepak_bola_lemmatized_text = " ".join(token_sepak_bola_lemmatized)

# Tampilkan hasilnya
print(token_sepak_bola_lemmatized_text)

# Proses mengubah list menjadi teks
token_keuangan_lemmatized_text = " ".join(token_keuangan_lemmatized)

# Tampilkan hasilnya
print(token_keuangan_lemmatized_text)

# Setelah itu gabungkan ketiga teks tersebut
teks_all_clean = [token_kesehatan_lemmatized_text, token_sepak_bola_lemmatized_text, token_keuangan_lemmatized_text]

"""------

# **Pembersihan Data Test**

**Teks baru yang ingin diklasifikasikan topiknya:** <br>
"Cristiano Ronaldo came off the bench to earn Manchester United a hard-fought 2-1 victory at Everton in the Premier League on Sunday, taking his career goal tally to 700 in the process. Just as United did last weekend in their derby mauling at the hands of local rivals Manchester City, they again found themselves behind early on at Goodison Park after Alex Iwobi curled a sublime strike into the net from 20 metres."
"""

text_baru = "Cristiano Ronaldo came off the bench to earn Manchester United a hard-fought 2-1 victory at Everton in the Premier League on Sunday, taking his career goal tally to 700 in the process. Just as United did last weekend in their derby mauling at the hands of local rivals Manchester City, they again found themselves behind early on at Goodison Park after Alex Iwobi curled a sublime strike into the net from 20 metres."

"""## Pastikan lower case"""

# Pastikan dalam lowercase
text_baru = text_baru.lower()

"""## Tokenization untuk memeriksa tiap kata (nantinya)"""

# Import library nltk
from nltk import tokenize

# Proses tokenisasi untuk teks baru
token_baru = tokenize.word_tokenize(text_baru)

# Tampilkan hasilnya
print(token_baru)

"""## Hapus stopwords & punctuations"""

# Import library
import string
from nltk import corpus

# Stopwords pada bahasa inggris
stopword_english = corpus.stopwords.words('english')

# Punctuations
str_punct = string.punctuation

# Proses menghapus stopwords dan punctuations pada token baru
for kata in token_baru:
    if(kata in stopword_english or kata in str_punct):
        token_baru.remove(kata)

# Tampilkan hasilnya
print(token_baru)

"""## Lemmatization"""

# Import library yang dibutuhkan
from nltk import stem

# Buat object dari class WordNetLemmatizer
lemmatizer = stem.WordNetLemmatizer()

# Buat list kosong untuk menampung hasil lemmatization
token_baru_lemmatized = list()

# Proses lemmatization pada token baru
for kata in token_baru:
    lemmatized = lemmatizer.lemmatize(kata, pos = 'v')
    token_baru_lemmatized.append(lemmatized)

# Tampilkan hasilnya
print(token_baru_lemmatized)

"""## Ubah menjadi teks kembali"""

# Proses mengubah list menjadi teks
teks_baru_all_clean = ' '.join(token_baru_lemmatized)

# Tampilkan hasilnya
print(teks_baru_all_clean)

"""# **Proses Klasifikasi Teks**

## Gabung Data Latih dan Data Test untuk dicari BoW nya
"""

# Sebelum digabung (data latih)
print(teks_all_clean)

# Gabung data latih dan data test
all_clean_text = teks_all_clean.copy()
all_clean_text.append(teks_baru_all_clean)

# Setelah digabung (data latih + data test)
all_clean_text

"""## Bag Of Words"""

from sklearn.feature_extraction.text import CountVectorizer

# Membuat objek CountVectorizer
vectorizer = CountVectorizer()

# Mengubah teks menjadi vektor fitur
vektor_fitur = vectorizer.fit_transform(all_clean_text).toarray()

# Mendapatkan daftar fitur
fitur = vectorizer.get_feature_names_out()

# Menampilkan hasil
print("Daftar Fitur:")
print(fitur)

print("\nVektor Fitur:")
print(vektor_fitur)

import math

# Normalisasi
bow_texts_norm = []
for bow in vektor_fitur:
    length = math.sqrt(sum(i*i for i in bow))
    bow_norm = bow / length
    bow_texts_norm.append(bow_norm)
    print('Bow : ', bow)
    print('Panjang : ', length)
    print('Normalisasi : ', bow_norm, '\n')

# Perhitungan similarity menggunakan dot product
similarity_vector = []
banyak_data_latih = len(bow_texts_norm) - 1

bow_norm_query = bow_texts_norm[banyak_data_latih]
for bow in bow_texts_norm[:banyak_data_latih]:
    similarity_vector.append(sum(i*j for i, j in zip(bow, bow_norm_query)))

# Tampilkan hasilnya
print(similarity_vector)

# Proses pencarian similarity paling tinggi
id_max_sim = similarity_vector.index(max(similarity_vector))

if (id_max_sim == 0):
    print ("Teks baru diklasifikasikan dalam topik Kesehatan Mental")
elif (id_max_sim == 1):
    print ("Teks baru diklasifikasikan dalam topik Sepak Bola")
elif (id_max_sim == 2):
    print ("Teks baru diklasifikasikan dalam topik Pasar Saham")